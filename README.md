
# Ex.No: 2 	Evaluation of 2024 Prompting Tools Across Diverse AI Platforms: ChatGPT, Claude, Bard, Cohere Command, and Meta 
### DATE:                                                                            
### REGISTER NUMBER : 
 
 EXPRIMENT 2 
 s.manoj kumar
 (212222040097)
Within a specific use case (e.g., summarizing text, answering technical questions), compare the 
performance, user experience, and response quality of prompting tools across these different 
AI platforms.
1.SUMARIZING TEXT
(CHAT GPT)
When would you use a hashmap over a binary search tree (BST)?
When would you use a hashmap over a binary search tree (BST)?
When to use a hashmap:
When to use a BST (especially a balanced one):
When would you use a hashmap over a binary search tree (BST)?
You would typically use a hashmap over a BST when:




Feature Hashmap Binary Search Tree (BST)
Average Lookup O(1) O(log n)
Average Insert O(1) O(log n)
Average Delete O(1) O(log n)
Worst-Case Lookup O(n) (due to collisions) O(n) (for skewed trees)
Worst-Case Insert O(n) (due to 
resizing/collisions)
O(n) (for skewed trees)
Worst-Case Delete O(n) (due to collisions) O(n) (for skewed trees)
Ordering Not maintained Elements are sorted (in￾order)
When would you use a hashmap over a binary search tree (BST)?
3.performance, user experience, and response quality of prompting tools 
across these different AI platforms.
 Speed: Fast, particularly with GPT-4 Turbo.
 Formatting: Clean and structured summaries.
 Reliability: Very consistent output, handles long context well.
 Intuitive UI; conversation history and memory features enhance experience.
 Temperature & tone not directly adjustable in free plan, but easy to guide with prompts.
 Pro plan allows for GPT-4 Turbo with 128k context—great for long documents.
 Very strong summarization skills—balances brevity and meaning.
 Captures nuances, especially in academic or technical documents.
 Good at paragraph-level reasoning.
 Speed: Slightly slower than GPT-4 Turbo, but acceptable.
 Context: Extremely strong—can handle up to 200k tokens (ideal for long texts).
 Formatting: Simple and readable, but less stylized than GPT outputs.
 Clean interface, minimal distractions.
 Fewer options for fine-tuning style or length in the free UI.
 Prioritizes safe, balanced summaries—often errs on the side of caution.
 Excellent for faithful summaries with minimal hallucination.
 Tends to preserve original tone and hierarchy of ideas.
 May be overly verbose or cautious unless prompted otherwise.
 Speed: Fast responses.
 Reliability: Occasionally cuts off or gives general summaries if prompt isn’t specific.
 Formatting: Generally clean, sometimes overly concise.
 Integrated with Google Docs and Workspace, good for productivity.
 UI feels more utilitarian than conversational.
 Can sometimes misinterpret long documents without chunking.
 Gets the gist but sometimes oversimplifies.
 Better for layman summaries than technical fidelity.
 Not as strong in preserving structure of academic documents.
 Speed: Fast (smaller models), slower (larger).
 Reliability: Depends on host platform—less consistent UI experience.
 Formatting: Varies widely—needs more prompt engineering.
 Often open-source interface—less polished than major players.
 Great for developers and tinkerers, not ideal for general users.
 Requires manual work to break down long documents.
 Adequate for general summaries, but weaker on nuance and structure.
 Often surface-level, especially on complex or technical text.
 Models like Mixtral or Mistral-Instruct show promise but still trail GPT/Claude.
Final Comparison Table
plateform performance 
(Speed/Reliability)
UX & Ease of Use Summary Quality
ChatGPT ⭐⭐⭐⭐☆ (fast, 
polished)
⭐⭐⭐⭐⭐ (best-in￾class UI)
⭐⭐⭐⭐⭐ (balanced, 
nuanced)
Claude ⭐⭐⭐⭐☆ (slower but 
powerful)
⭐⭐⭐⭐☆
(minimalist)
⭐⭐⭐⭐☆ (accurate, 
safe)
Gemini ⭐⭐⭐⭐☆ (fast, 
less context)
⭐⭐⭐⭐☆ (well￾integrated)
⭐⭐⭐⭐ (broad but 
light)
Mistral ⭐⭐⭐☆☆ (platform 
dependent)
⭐⭐☆☆☆ (developer 
focus)
⭐⭐☆☆☆ (needs 
refinement)
